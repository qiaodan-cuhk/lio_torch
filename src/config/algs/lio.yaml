# --- specific parameters ---
#  LIO Actor Critic Params

# action selector
mask_before_softmax: True
action_selector: "multinomial"
agent_output_type:  pi_logits  # "q"

onehot_actions: false

epsilon_start: 0.5
epsilon_finish: 0.05
epsilon_anneal_time: 50000 # 100000
epsilon_zero: # None(empty): never zero; 1e6: 1M

buffer_size: 5000 # 12
batch_size_run: 1
batch_size: 16 # 8
test_nepisode: 4
test_interval: 200 # steps


name: "lio"
agent: "lio"
runner: "episode_lio"
learner: "lio_learner"
mixer:  # Mixer becomes None
mac: "lio_mac"
double_q: True
# critic_type: 
use_actor_critic: true
cuda_id: 1



# critic params
obs_individual_obs: false
obs_other_actions: false
obs_last_action: false
obs_agent_id: false

# 不可以使用 1e-4，会被识别成str
# training params
lr_actor: 0.0001
lr_cost: 0.00001
lr_opp: 0.001
lr_reward: 0.001
lr_v: 0.001
optimizer: 'adam'
reg: 'l1'
reg_coeff: 0.0001  # float, or 'linear', or 'adaptive'
tau: 0.01

# update the target network every {} episodes
target_update_interval: 20 # episodes
gamma_env: 0.99
gamma_inc: 0.995
lr_env: 0.0001
lr_inc: 0.00001


use_cuda: True
save_model: True # Save the models to disk
save_model_interval: 100000 #100000 # Save models after this many timesteps
log_interval: 1000 # Log summary of stats after every {} timesteps
runner_log_interval: 1000 # Log runner stats (not test stats) every {} timesteps
learner_log_interval: 1000 # Log training stats every {} timesteps
use_tensorboard: True


# 用于 lio agent 实例化
alg_args:

  # ego lio params
  # rgb_input: True  # True
  other_action_1hot: True
  r_multiplier: 2.0  #控制inc范围，整数

  n_inc_actions: 3 # 0,1,2 = NO, +, -
  consider_others_inc: False


  # other lio params
  lio_asymmetric: false # 如果agent num=2，那么就是true
  idx_recipient: 1  # 设定接收者id，在2 agents情况使用
  entropy_coeff: 0.1
  budget_constraint: false
  include_cost_in_chain_rule: false
  separate_cost_optimizer: false

  


  # a2c NN params
  kernel: [3, 3]
  n_filters: 6
  stride: [1, 1]

  actor_h1: 64
  actor_h2: 64

  inc_h1: 64
  inc_h2: 64

  critic_h1: 64
  critic_h2: 64

  # algorithms
  incentive: False
  incentive_ratio: 1.0
  incentive_cost:  0.1

  sim_loss_weight: 0.01
  sim_threshold: 0.7
  sim_horizon: 10

  

  

  


# # Projects/lio/lio/alg/config_ssd_lio.yaml
# alg:
#   n_episodes: 50000
#   n_eval: 10
#   n_test: 3
#   period: 1000


# main:
#   dir_name: 'small_n2_lio'
#   exp_name: 'cleanup'
#   max_to_keep: 12
#   model_name: 'model.ckpt'
#   save_period: 100000
#   save_threshold: 40
#   seed: 12340
#   summarize: false
